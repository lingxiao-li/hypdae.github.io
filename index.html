<!DOCTYPE html>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>HypDAE: Hyperbolic Diffusion Autoencoders for Hierarchical Few-shot Image Generation</title>
    <link href="./DreamBooth_files/style.css" rel="stylesheet">
</head>

<body>
<div class="content">
  <h1><strong>HypDAE: Hyperbolic Diffusion Autoencoders for Hierarchical Few-shot Image Generation</strong></h1>
  <p id="authors"><span><a href="https://lingxiao-li.github.io/">Lingxiao Li</a><a href="https://scholar.google.com/citations?user=V2KHBeUAAAAJ">Kaixuan Fan</a><a href="https://boqinggong.github.io/">Boqing Gong</a><a href="https://xyue.io/">Xiangyu Yue</a></span><br>
    <span style="font-size: 24px">MMLab, The Chinese University of Hong Kong & Boston University</span></p>
  <br>
  <img src="./HypDAE_images/Hierarchy-1.png" class="teaser-gif" style="width:100%;"><br>
  <h3 style="text-align:center">Illustration of hierarchical text-image representation in hyperbolic space. Hyperbolic space provides a natural and compact encoding for semantic hierarchies in large datasets. Adjusting high-level, identity-relevant attributes alters an image's identity, while modifying low-level, identity-irrelevant attributes produces variations within the same identity.</h3>
  <font size="+2">
          <p style="text-align: center;">
            <a href="https://arxiv.org/abs/2411.17784" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/lingxiao-li/HypDAE" target="_blank">[Code]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="DreamBooth_files/bibtex.txt" target="_blank">[BibTeX]</a>
          </p>
  </font>
</div>

<div class="content">
  <h2 style="text-align:center;">Abstract</h2>
  <p>Few-shot image generation aims to generate diverse and high-quality images for an unseen class given only a few examples in that class. A key challenge in this task is balancing category consistency and image diversity, which often compete with each other. Moreover, existing methods offer limited control over the attributes of newly generated images. In this work, we propose <strong>Hyperbolic Diffusion Autoencoders (HypDAE)</strong>, a novel approach that operates in hyperbolic space to capture hierarchical relationships among images from seen categories. By leveraging pre-trained foundation models, HypDAE generates diverse new images for unseen categories with exceptional quality by varying stochastic subcodes or semantic codes. Most importantly, the hyperbolic representation introduces an additional degree of control over semantic diversity through the adjustment of radii within the hyperbolic disk. Extensive experiments and visualizations demonstrate that HypDAE significantly outperforms prior methods by achieving a better balance between preserving category-relevant features and promoting image diversity with limited data. Furthermore, HypDAE offers a highly controllable and interpretable generation process.</p>
</div>

<div class="content">
  <h2>Introduction</h2>
  <p>Generative models have succeeded in generating high-fidelity and realistic images, partially thanks to a large volume of high-quality data for model training. However, with the widespread presence of long-tail distributions and data imbalances across image categories, there are many scenarios in the real world where it is impossible to collect sufficient samples of certain categories for model training. It is difficult for generative models trained on well-sampled categories to generate realistic and diverse images for a novel category given only a few examples. This challenging task is known as <strong>few-shot image generation</strong>, which aims to synthesize images that preserve the category-level identity of the limited input samples.</p>
  
  <p>Existing few-shot image generation methods are primarily GAN-based and fall into three categories: <em>transfer-based</em> approaches, which use meta-learning or domain adaptation for cross-category generalization but often face limited transferability; <em>fusion-based</em> approaches, which fuse features from multiple exemplars but tend to produce outputs overly similar to the inputs; and <em>transformation-based</em> approaches, which apply intra-category perturbations without fine-tuning but often lack diversity.</p>
  
  <p>In contrast to prior methods, recent work highlights the importance of modeling hierarchical structures in few-shot image generation. Similar to language, images also exhibit semantic hierarchies, where each image can be viewed as a composition of attributes at different levels. High-level, identity-relevant attributes (e.g., gender or age) define the semantic core of a category, while low-level, identity-irrelevant attributes (e.g., expression or hairstyle) introduce intra-class variation. Capturing this hierarchical organization is essential for generating diverse yet category-consistent images. <strong>Hyperbolic space</strong> provides a natural embedding for such structures, as it can represent tree-like relationships with low distortion.</p>
  <br>
  <img class="summary-img" src="./HypDAE_images/Poincare_disk-1.png" style="width:100%;"> <br>
  <p><em>Illustration of the property of hyperbolic space on the Poincaré disk.</em> Given two latent codes of Maltese dog on the edge of Poincaré disk, the geodesic between these two points is the red curve rather than a straight line in Euclidean space. Therefore, their average latent code is calculated closer to the center, which can be viewed as the "parent" of the child codes. One can generate diverse images without changing the category by moving the latent code from one child to another of the same parent in the hyperbolic space.</p>
</div>

<div class="content">
  <h2>Method</h2>
  <p>We design a two-stage model for HypDAE: 1) In Stage I, a diffusion autoencoder maps input images to meaningful latent codes, serving as conditions for the pre-trained Stable Diffusion (SD). To enhance diversity and prevent direct replication, a content bottleneck and strong augmentation techniques are applied. 2) In Stage II, a hyperbolic encoder-decoder projects visual features from Stage I into hyperbolic space using supervised classification loss and then reconstructs them in Euclidean space. This process captures hierarchical relationships within the image corpus, facilitating the generation of diverse images by manipulating latent codes within the same category.</p>
  <br>
  <img class="summary-img" src="./HypDAE_images/Pipeline-1.png" style="width:100%;"> <br>
  <p><em>The overview of HypDAE.</em> The hyperbolic autoencoder consists of a "semantic" encoder that maps the reference image to the semantic code (x→c), and a stable diffusion model that acts both as a "stochastic" encoder (x→z_T) and a diffusion decoder ((c′,z_T)→x′). Here, c captures the high-level semantics while z_T captures low-level stochastic variations; they can be decoded back with high fidelity. The semantic code can be edited and used as the condition for the diffusion decoder to generate diverse new images with the same category.</p>
  <br>
  
  <h3>Hyperbolic Space Representation</h3>
  <p>To manipulate latent codes in hyperbolic space, we define a bijective map from R^n to D^n to map Euclidean vectors to the hyperbolic space and vice versa. The <em>exponential map</em> maps from the tangent spaces into the manifold, while the <em>logarithmic map</em> is the reverse operation. This enables us to perform optimization in the tangent space while maintaining the geometric properties of the hyperbolic manifold.</p>
</div>


<div class="content">
  <h2>Results</h2>
  <p>We evaluate HypDAE on multiple few-shot image generation benchmarks including Animal Faces, Flowers, VGGFaces, and NABirds datasets. HypDAE demonstrates superior performance in generating diverse and high-quality images while maintaining category consistency.</p>
  <br>
  <img class="summary-img" src="./HypDAE_images/Generation-1.png" style="width:100%;"> <br>
  <p><em>One-shot image generation from HypDAE on Animal Faces, Flowers, VGGFaces, and NABirds.</em> Our method generates diverse and high-quality images that preserve the category-level identity while introducing meaningful variations.</p>
  <br>
  
  <h3>Hierarchical Generation</h3>
  <img class="summary-img" src="./HypDAE_images/Hierarchical_Generation-1.png" style="width:100%;"> <br>
  <p><em>Hierarchical generation results showing controllable diversity.</em> By adjusting the radius in hyperbolic space, we can control the semantic diversity of generated images while maintaining category consistency.</p>
  
  <h3>Qualitative Comparison</h3>
  <img class="summary-img" src="./HypDAE_images/Comparison-1.png" style="width:100%;"> <br>
  <p><em>Qualitative comparison with state-of-the-art few-shot image generation methods.</em> HypDAE achieves better balance between category consistency and image diversity compared to existing approaches.</p>
</div>

<div class="content">
  <h2>Applications</h2>
  <p>HypDAE enables various downstream applications including controllable image editing and semantic interpolation in hyperbolic space.</p>
  <br>
  <img class="summary-img" src="./HypDAE_images/Image_Editing-1.png" style="width:100%;"> <br>
  <p><em>Image editing applications.</em> HypDAE enables fine-grained control over semantic attributes while preserving the overall identity of the generated images.</p>
</div>


<div class="content">
  <h2>Ablation Studies</h2>
  <p>We conduct comprehensive ablation studies to validate the effectiveness of each component in HypDAE.</p>
  <img class="summary-img" src="./HypDAE_images/Ablation_Generation-1.png" style="width:100%;">
    <br>
    <p><em>Ablation study on key components of HypDAE.</em> The study demonstrates the importance of hyperbolic space representation and the two-stage architecture for achieving high-quality few-shot generation.</p>
</div>

<div class="content">
  <h2>More Visualizations</h2>
    <p>
        <h3>Additional Generation Results</h3>
    </p>
  <br>
  <img class="summary-img" src="./HypDAE_images/More_Generation-1.png" style="width:100%;"> <br>
  <p><em>Additional generation results from HypDAE.</em> Our method consistently generates high-quality and diverse images across different categories while maintaining semantic consistency.</p>
</div>

<div class="content">
  <h2>BibTex</h2>
  <code>@misc{li2024hypdae,<br>
  &nbsp;&nbsp;title={HypDAE: Hyperbolic Diffusion Autoencoders for Hierarchical Few-shot Image Generation},<br>
  &nbsp;&nbsp;author={Lingxiao Li and Kaixuan Fan and Boqing Gong and Xiangyu Yue},<br>
  &nbsp;&nbsp;year={2024},<br>
  &nbsp;&nbsp;eprint={2411.17784},<br>
  &nbsp;&nbsp;archivePrefix={arXiv},<br>
  &nbsp;&nbsp;primaryClass={cs.CV}<br>
  }</code>
</div>

<div class="content" id="acknowledgements">
  <p><strong>Acknowledgements</strong>: We thank <a href="https://dreambooth.github.io">DreamBooth</a> for the page templates.</p>
</div>
</body>
</html>
