<!DOCTYPE html>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>HypDAE: Hyperbolic Diffusion Autoencoders for Hierarchical Few-shot Image Generation</title>
    <link href="./DreamBooth_files/style.css" rel="stylesheet">
    <script type="text/javascript" src="./DreamBooth_files/jquery.mlens-1.0.min.js"></script> 
    <script type="text/javascript" src="./DreamBooth_files/jquery.js"></script>
</head>

<body>
<div class="content">
  <h1><strong>HypDAE: Hyperbolic Diffusion Autoencoders for Hierarchical Few-shot Image Generation</strong></h1>
  <p id="authors"><span><a href="https://lingxiao-li.github.io/">Lingxiao Li</a><sup>1,2</sup>&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://scholar.google.com/citations?user=V2KHBeUAAAAJ">Kaixuan Fan</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://boqinggong.github.io/">Boqing Gong</a><sup>2*</sup>&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://xyue.io/">Xiangyu Yue</a><sup>1*</sup></span><br>
    <span style="font-size: 24px"><sup>1</sup>MMLab, The Chinese University of Hong Kong &nbsp;&nbsp;&nbsp;&nbsp; <sup>2</sup>Boston University</span></p>
  <br>
  <img src="./HypDAE_figures/Hierarchy.png" class="teaser-gif" style="width:100%;"><br>
  <h3 style="text-align:center">Illustration of hierarchical text-image representation in hyperbolic space. Hyperbolic space provides a natural and compact encoding for semantic hierarchies in large datasets. Adjusting high-level, identity-relevant attributes alters an image's identity, while modifying low-level, identity-irrelevant attributes produces variations within the same identity.</h3>
  <font size="+2">
          <p style="text-align: center;">
            <a href="https://arxiv.org/abs/2411.17784" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/lingxiao-li/HypDAE" target="_blank">[Code]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="DreamBooth_files/bibtex.txt" target="_blank">[BibTeX]</a>
          </p>
  </font>
</div>

<div class="content">
  <h2 style="text-align:center;">Abstract</h2>
  <p>Few-shot image generation aims to generate diverse and high-quality images for an unseen class given only a few examples in that class. A key challenge in this task is balancing category consistency and image diversity, which often compete with each other. Moreover, existing methods offer limited control over the attributes of newly generated images. In this work, we propose <strong>Hyperbolic Diffusion Autoencoders (HypDAE)</strong>, a novel approach that operates in hyperbolic space to capture hierarchical relationships among images from seen categories. By leveraging pre-trained foundation models, HypDAE generates diverse new images for unseen categories with exceptional quality by varying stochastic subcodes or semantic codes. Most importantly, the hyperbolic representation introduces an additional degree of control over semantic diversity through the adjustment of radii within the hyperbolic disk. Extensive experiments and visualizations demonstrate that HypDAE significantly outperforms prior methods by achieving a better balance between preserving category-relevant features and promoting image diversity with limited data. Furthermore, HypDAE offers a highly controllable and interpretable generation process.</p>
</div>

<div class="content">
  <h2>Introduction</h2>
  <p>Generative models have succeeded in generating high-fidelity and realistic images, partially thanks to a large volume of high-quality data for model training. However, with the widespread presence of long-tail distributions and data imbalances across image categories, there are many scenarios in the real world where it is impossible to collect sufficient samples of certain categories for model training. It is difficult for generative models trained on well-sampled categories to generate realistic and diverse images for a novel category given only a few examples. This challenging task is known as <strong>few-shot image generation</strong>, which aims to synthesize images that preserve the category-level identity of the limited input samples.</p>
  
  <p>Existing few-shot image generation methods are primarily GAN-based and fall into three categories: <em>transfer-based approaches</em>, which use meta-learning or domain adaptation for cross-category generalization but often face limited transferability; <em>fusion-based approaches</em>, which fuse features from multiple exemplars but tend to produce outputs overly similar to the inputs; and <em>transformation-based approaches</em>, which apply intra-category perturbations without fine-tuning but often lack diversity. Recent diffusion-based methods for object-level personalization focus on instance identity, require test-time fine-tuning, and depend on prompt engineering, making them incompatible with our category-level setting without textual inputs or model updates.</p>
  
  <p>To address these limitations, we propose <strong>HypDAE (Hyperbolic Diffusion Autoencoders)</strong>, which leverages the unique properties of hyperbolic space to model hierarchical semantic relationships in few-shot image generation. Our method operates in hyperbolic space to capture both identity-relevant features (to maintain category consistency) and identity-irrelevant features (to enhance diversity), providing unprecedented control over the generation process through hierarchical semantic editing.</p>
  <br>
  <img class="summary-img" src="./HypDAE_figures/Pipeline.png" style="width:100%;"> <br>
  <p style="text-align:center; font-style:italic;">Overview of the HypDAE framework showing the hyperbolic diffusion autoencoder architecture for hierarchical few-shot image generation.</p>
</div>

<div class="content">
  <h2>Method</h2>
  <p>To generate diverse new images from a few reference images while preserving their identity, it is essential for our model to capture both <strong>identity-relevant features</strong> (to maintain identity) and <strong>identity-irrelevant features</strong> (to enhance diversity). To achieve this, we design a diffusion autoencoder that extracts elementary identity-relevant features via a semantic encoder and identity-irrelevant features via a stochastic encoder. Furthermore, a <strong>hyperbolic encoder-decoder</strong> is introduced to further disentangle high-order semantic features.</p>
  
  <h3>Hierarchical Learning in Hyperbolic Space</h3>
  <p>A key challenge in multi-level semantic editing is deriving a hierarchical representation from real images. To address this, we utilize <strong>hyperbolic space</strong> as the latent space, given its suitability for hierarchical structures. Unlike Euclidean spaces (zero curvature) or spherical spaces (positive curvature), hyperbolic spaces exhibit negative curvature, making them ideal for modeling hierarchical data. As a continuous analog of trees, hyperbolic space enables hierarchical representation through its exponential radius growth, facilitating structured modeling across text, images, and videos.</p>
  <br>
  <img class="summary-img" src="./HypDAE_figures/Feature_Fusion.png" style="width:100%;"> <br>
  <p style="text-align:center; font-style:italic;">Illustration of feature fusion in hyperbolic space showing how semantic and stochastic features are combined.</p>
  
  <h3>Hyperbolic Diffusion Framework</h3>
  <p>Our HypDAE framework integrates hyperbolic representations into diffusion models through a carefully designed architecture that enables stable training and generation. The hyperbolic embeddings serve as diffusion conditions, enabling scalable and interpretable few-shot generation with explicit control over semantic hierarchies.</p>
</div>


<div class="content">
  <h2>Results</h2>
  <p>We evaluate HypDAE on standard few-shot image generation benchmarks and demonstrate significant improvements over existing methods. Our approach achieves superior performance in terms of both image quality and diversity metrics while providing unprecedented control over the generation process.</p>
  
  <h3>Few-shot Generation Results</h3>
  <p>HypDAE generates high-quality, diverse images that preserve category identity while introducing meaningful variations. The hierarchical control in hyperbolic space allows fine-grained manipulation of semantic attributes.</p>
  <br>
  <img class="summary-img" src="./HypDAE_figures/Hierarchical_Generation.png" style="width:100%;"> <br>
  <p style="text-align:center; font-style:italic;">Examples of hierarchical few-shot image generation showing controllable semantic diversity.</p>
  
  <h3>Comparison with State-of-the-Art Methods</h3>
  <p>Quantitative and qualitative comparisons demonstrate that HypDAE significantly outperforms existing few-shot generation methods across multiple datasets and evaluation metrics.</p>
  <br>
  <img class="summary-img" src="./HypDAE_figures/Comparison.png" style="width:100%;"> <br>
  <p style="text-align:center; font-style:italic;">Comparison with state-of-the-art few-shot image generation methods showing superior quality and diversity.</p>
</div>

<div class="content">
  <h2>Controllable Generation</h2>
  <p>One of the key advantages of HypDAE is its ability to provide fine-grained control over the generation process through hyperbolic semantic editing. By adjusting the radius and position in hyperbolic space, users can control the level of semantic diversity and specific attributes of generated images.</p>
  <br>
  <img class="summary-img" src="./HypDAE_figures/Generation.png" style="width:100%;"> <br>
  <p style="text-align:center; font-style:italic;">Demonstration of controllable generation with varying semantic diversity levels.</p>
</div>

<div class="content">
  <h2>Out-of-Distribution Generalization</h2>
  <p>HypDAE demonstrates strong generalization capabilities on out-of-distribution data, successfully generating high-quality images for unseen categories that differ significantly from the training distribution.</p>
  <br>
  <img class="summary-img" src="./HypDAE_figures/OOD.png" style="width:100%;"> <br>
  <p style="text-align:center; font-style:italic;">Out-of-distribution generation results showing robust generalization capabilities.</p>
</div>


<div class="content">
<div class="content">
  <h2>Ablation Studies</h2>
  <p>We conduct comprehensive ablation studies to analyze the contribution of each component in HypDAE. The studies demonstrate the importance of hyperbolic space representation and the effectiveness of our hierarchical semantic control mechanism.</p>
  
  <h3>Component Analysis</h3>
  <p>Ablation study on the key components of HypDAE, showing the importance of hyperbolic representation and hierarchical semantic encoding for few-shot generation quality.</p>
  <img class="summary-img" src="./HypDAE_figures/Ablation_Generation.png" style="width:100%;">
    <br>
    <p style="text-align:center; font-style:italic;">Ablation study results for generation components.</p>
    <br>
    
  <h3>Semantic Editing Ablation</h3>
  <p>Analysis of different levels of semantic control and their impact on generation quality and diversity.</p>
  <img class="summary-img" src="./HypDAE_figures/Ablation_Editing.png" style="width:100%;">
  <p style="text-align:center; font-style:italic;">Ablation study on semantic editing capabilities.</p>
</div>

<div class="content">
  <h2>User Study</h2>
  <p>We conduct comprehensive user studies to evaluate the quality and controllability of HypDAE's generated images. Human evaluators consistently rate HypDAE-generated images higher in terms of quality, diversity, and semantic consistency.</p>
  <br>
  <img class="summary-img" src="./HypDAE_figures/User_Study.png" style="width:100%;"> <br>
  <p style="text-align:center; font-style:italic;">Results from user study evaluations showing superior performance across multiple metrics.</p>
</div>

<div class="content">
  <h2>Interpolation and Semantic Editing</h2>
  <p>HypDAE enables smooth interpolation in the hyperbolic latent space, allowing for continuous semantic editing and morphing between different identities while maintaining image quality.</p>
  <br>
  <img class="summary-img" src="./HypDAE_figures/Interpolation.png" style="width:100%;"> <br>
  <p style="text-align:center; font-style:italic;">Smooth interpolation results in hyperbolic space demonstrating controllable semantic editing capabilities.</p>
</div>

<div class="content">
  <h2>BibTeX</h2>
  <code>@article{li2024hypdae,<br>
  &nbsp;&nbsp;title={HypDAE: Hyperbolic Diffusion Autoencoders for Hierarchical Few-shot Image Generation},<br>
  &nbsp;&nbsp;author={Lingxiao Li and Kaixuan Fan and Boqing Gong and Xiangyu Yue},<br>
  &nbsp;&nbsp;journal={arXiv preprint arXiv:2411.17784},<br>
  &nbsp;&nbsp;year={2024}<br>
  }</code>
</div>

<div class="content" id="acknowledgements">
  <p><strong>Acknowledgements</strong>: We thank <a href="https://dreambooth.github.io">DreamBooth</a> for the page templates.</p>
</div>
</body>
</html>
